{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image Classification using Satellite Images and CNNs: Preprocessing, Analysis and Evaluation\n","### By: Christian Tan_PH"]},{"cell_type":"markdown","metadata":{},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This notebook provides an in-depth solution for training a machine learning model for image classification using satellite image chips with various land cover/land use and atmospheric conditions. <br> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It covers all essential stages such as data preparation, data analysis, model definition, training, evaluation and prediction. The code employs various libraries like numpy, pandas, matplotlib, tensorflow, keras, and scikit-learn to perform different tasks. The CNN architecture is used to train the model, which is a robust model for image classification tasks.<br><br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This code is perfect as a starting point for building similar models for image classification tasks and can be easily adapted to different datasets and requirements."]},{"cell_type":"markdown","metadata":{},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:35:05.159967Z","iopub.status.busy":"2023-01-13T01:35:05.159430Z","iopub.status.idle":"2023-01-13T01:35:16.733343Z","shell.execute_reply":"2023-01-13T01:35:16.731936Z","shell.execute_reply.started":"2023-01-13T01:35:05.159854Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","\n","import os\n","import gc\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential \n","\n","import keras as k\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\n","\n","import cv2\n","from tqdm import tqdm\n","from collections import Counter\n","\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import fbeta_score\n","\n","import plotly.express as px\n"]},{"cell_type":"markdown","metadata":{},"source":["# Loading The Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:35:16.737351Z","iopub.status.busy":"2023-01-13T01:35:16.736368Z","iopub.status.idle":"2023-01-13T01:35:17.705149Z","shell.execute_reply":"2023-01-13T01:35:17.703217Z","shell.execute_reply.started":"2023-01-13T01:35:16.737273Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train files: 40479, test files: 40669\n"]}],"source":["# Define the base path for the dataset\n","path = \"../input/planets-dataset/planet/planet/\"\n","\n","# Join the base path with the train-jpg folder\n","path_train = os.path.join(path, \"train-jpg\")\n","\n","# Join the base path with the test-jpg folder\n","path_test = os.path.join(path, \"test-jpg\")\n","\n","# Use the os.listdir function to get the number of files in the train-jpg and test-jpg folders\n","print(\n","    f\"train files: {len(os.listdir(path_train))}, \"\n","    f\"test files: {len(os.listdir(path_test))}\"\n",")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:35:17.707804Z","iopub.status.busy":"2023-01-13T01:35:17.706614Z","iopub.status.idle":"2023-01-13T01:35:17.811315Z","shell.execute_reply":"2023-01-13T01:35:17.809240Z","shell.execute_reply.started":"2023-01-13T01:35:17.707760Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(40479, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_0</td>\n","      <td>haze primary</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_1</td>\n","      <td>agriculture clear primary water</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_3</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_4</td>\n","      <td>agriculture clear habitation primary road</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  image_name                                       tags\n","0    train_0                               haze primary\n","1    train_1            agriculture clear primary water\n","2    train_2                              clear primary\n","3    train_3                              clear primary\n","4    train_4  agriculture clear habitation primary road"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Define the path to the train_classes.csv file\n","path_train_class = os.path.join(path, \"train_classes.csv\")\n","\n","# Read the train_classes.csv file and store it in a DataFrame\n","df_train = pd.read_csv(path_train_class)\n","\n","# Print the shape of the DataFrame\n","print(df_train.shape)\n","\n","# Display the first 5 rows of the DataFrame\n","df_train.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Exploring and Understanding the Labels in the dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:35:17.813878Z","iopub.status.busy":"2023-01-13T01:35:17.812943Z","iopub.status.idle":"2023-01-13T01:35:17.876656Z","shell.execute_reply":"2023-01-13T01:35:17.874602Z","shell.execute_reply.started":"2023-01-13T01:35:17.813804Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["total of 116278 non-unique tags in all training images\n","average number of labels per image 2.8725511993873365\n"]}],"source":["# Number Of Unique Tags In The Dataset\n","# Avereage # Of Labels Per Image\n","\n","all_tags = [item for sublist in list(df_train['tags'].apply(lambda row: row.split(\" \")).values) for item in sublist]\n","print('total of {} non-unique tags in all training images'.format(len(all_tags)))\n","print('average number of labels per image {}'.format(1.0*len(all_tags)/df_train.shape[0]))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:35:17.881452Z","iopub.status.busy":"2023-01-13T01:35:17.880912Z","iopub.status.idle":"2023-01-13T01:35:19.586334Z","shell.execute_reply":"2023-01-13T01:35:19.584414Z","shell.execute_reply.started":"2023-01-13T01:35:17.881413Z"},"trusted":true},"outputs":[{"data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>                            <div id=\"35c1a604-4568-42c8-9d54-8ca0beaba1d5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"35c1a604-4568-42c8-9d54-8ca0beaba1d5\")) {                    Plotly.newPlot(                        \"35c1a604-4568-42c8-9d54-8ca0beaba1d5\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"total=%{marker.color}<br>tag=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[100,101,209,332,339,340,862,2089,2697,3660,4547,7261,7411,8071,12315,28431,37513],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[100,101,209,332,339,340,862,2089,2697,3660,4547,7261,7411,8071,12315,28431,37513],\"xaxis\":\"x\",\"y\":[\"conventional_mine\",\"blow_down\",\"slash_burn\",\"blooming\",\"artisinal_mine\",\"selective_logging\",\"bare_ground\",\"cloudy\",\"haze\",\"habitation\",\"cultivation\",\"partly_cloudy\",\"water\",\"road\",\"agriculture\",\"clear\",\"primary\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"total\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"tag\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"total\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"Tags distribution\"}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('35c1a604-4568-42c8-9d54-8ca0beaba1d5');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["# Label Distribution\n","\n","# Add a new column 'list_tags' to the DataFrame by splitting the 'tags' column on the space character\n","df_train[\"list_tags\"] = df_train.tags.str.split(\" \")\n","\n","# Get the values of the new column\n","row_tags = df_train.list_tags.values\n","\n","# Flatten the list of tags\n","tags = [tag for row in row_tags for tag in row]\n","\n","# Count the occurrences of each tag\n","counter_tags = Counter(tags)\n","\n","# Create a new DataFrame with the tag and total columns\n","df_tags = pd.DataFrame(\n","    {\"tag\": counter_tags.keys(), \"total\": counter_tags.values()}\n",").sort_values(\"total\")\n","\n","# Create a bar chart of the tag distribution using Plotly\n","fig = px.bar(df_tags, x=\"total\", y=\"tag\", orientation=\"h\", \n","             color=\"total\",\n",")\n","\n","# Update the chart title\n","fig.update_layout(title=\"Tags distribution\")\n","\n","# Show the chart\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Machine Learning\n","## Preparing the Data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:35:19.587864Z","iopub.status.busy":"2023-01-13T01:35:19.587508Z","iopub.status.idle":"2023-01-13T01:35:19.611435Z","shell.execute_reply":"2023-01-13T01:35:19.610141Z","shell.execute_reply.started":"2023-01-13T01:35:19.587835Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_0</td>\n","      <td>haze primary</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_1</td>\n","      <td>agriculture clear primary water</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_3</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_4</td>\n","      <td>agriculture clear habitation primary road</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  image_name                                       tags\n","0    train_0                               haze primary\n","1    train_1            agriculture clear primary water\n","2    train_2                              clear primary\n","3    train_3                              clear primary\n","4    train_4  agriculture clear habitation primary road"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Drop the created \"list_tags\" column\n","\n","df_train = df_train.drop(\"list_tags\", axis='columns')\n","df_train.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:35:19.614031Z","iopub.status.busy":"2023-01-13T01:35:19.613239Z","iopub.status.idle":"2023-01-13T01:41:33.604422Z","shell.execute_reply":"2023-01-13T01:41:33.603132Z","shell.execute_reply.started":"2023-01-13T01:35:19.613982Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 40479/40479 [06:02<00:00, 111.76it/s]\n"]}],"source":["# Initialization and Image Reading\n","\n","# Initialize empty lists to store the training images and their labels\n","x_train = []\n","y_train = []\n","\n","# Flatten the list of tags\n","flatten = lambda l: [item for sublist in l for item in sublist]\n","labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n","\n","# Create a label map for the unique tags in the dataset\n","label_map = {l: i for i, l in enumerate(labels)}\n","inv_label_map = {i: l for l, i in label_map.items()}\n","\n","# Loop through the training DataFrame\n","for f, tags in tqdm(df_train.values, miniters=1000):\n","    # Read the image file\n","    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n","    # Initialize an array of zeros for the targets\n","    targets = np.zeros(17)\n","    # Loop through the tags for the current image\n","    for t in tags.split(' '):\n","        # Set the corresponding target value to 1\n","        targets[label_map[t]] = 1 \n","    # Append the image and its labels to the appropriate lists\n","    x_train.append(cv2.resize(img, (64, 64)))  # Indicate the IMG Size\n","    y_train.append(targets)\n","\n","# Convert the lists to numpy arrays\n","x_train = np.array(x_train, np.float16) / 255.\n","y_train = np.array(y_train, np.uint8)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:41:33.607314Z","iopub.status.busy":"2023-01-13T01:41:33.606796Z","iopub.status.idle":"2023-01-13T01:41:42.625015Z","shell.execute_reply":"2023-01-13T01:41:42.623306Z","shell.execute_reply.started":"2023-01-13T01:41:33.607266Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data shape: (32383, 64, 64, 3)\n","Train label shape: (32383, 17)\n","Validation data shape: (8096, 64, 64, 3)\n","Validation label shape: (8096, 17)\n"]}],"source":["# Converting the lists of images and labels to numpy arrays and normalizing the pixel values of the images. \n","y_train = np.array(y_train, np.uint8)\n","x_train = np.array(x_train, np.float16) / 255.0\n","\n","# Splitting the data into train and validation sets. \n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n","\n","# Prints the shape of the training and validation data.\n","print(\"Train data shape:\",x_train.shape)\n","print(\"Train label shape:\",y_train.shape)\n","\n","print(\"Validation data shape:\",x_val.shape)\n","print(\"Validation label shape:\",y_val.shape)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:41:42.630563Z","iopub.status.busy":"2023-01-13T01:41:42.626854Z","iopub.status.idle":"2023-01-13T01:41:42.870781Z","shell.execute_reply":"2023-01-13T01:41:42.869802Z","shell.execute_reply.started":"2023-01-13T01:41:42.630501Z"},"trusted":true},"outputs":[{"data":{"text/plain":["100"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Free up some memory that is not being used by the program\n","gc.collect()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Establishing Evaluation Metrics for the Model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:41:42.872470Z","iopub.status.busy":"2023-01-13T01:41:42.872029Z","iopub.status.idle":"2023-01-13T01:41:42.889166Z","shell.execute_reply":"2023-01-13T01:41:42.887525Z","shell.execute_reply.started":"2023-01-13T01:41:42.872434Z"},"trusted":true},"outputs":[],"source":["# Defining a function that calculates the F-beta score for a given set of true labels and predicted labels.\n","# The function balances precision and recall and it is useful when there is an imbalance in the number of positive and negative examples in the data.\n","\n","def fbeta(y_true, y_pred, threshold_shift=0):\n","    beta = 2\n","\n","    # Clipping y_pred between 0 and 1\n","    y_pred = K.clip(y_pred, 0, 1)\n","\n","    # Rounding y_pred to binary values\n","    y_pred_bin = K.round(y_pred + threshold_shift)\n","\n","    # Counting true positives, false positives, and false negatives\n","    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n","    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n","    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n","\n","    # Calculating precision and recall\n","    precision = tp / (tp + fp)\n","    recall = tp / (tp + fn)\n","\n","    beta_squared = beta ** 2\n","    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:41:42.891812Z","iopub.status.busy":"2023-01-13T01:41:42.890994Z","iopub.status.idle":"2023-01-13T01:41:42.912172Z","shell.execute_reply":"2023-01-13T01:41:42.910200Z","shell.execute_reply.started":"2023-01-13T01:41:42.891761Z"},"trusted":true},"outputs":[],"source":["# This code defines a function that calculates the accuracy score for a given set of true labels and predicted labels.\n","def accuracy_score(y_true, y_pred, epsilon = 1e-4):\n","    \n","    # casting the true labels and predicted labels to float32\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n","    \n","    # counting the true positives\n","    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n","    \n","    # counting the false positives\n","    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n","    \n","    # counting the false negatives\n","    fn = tf.reduce_sum(y_true, axis = 1) - tp\n","    \n","    # casting the true labels and predicted labels to boolean\n","    y_true = tf.cast(y_true, tf.bool)\n","    y_pred = tf.cast(y_pred, tf.bool)\n","    \n","    # counting the true negatives\n","    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32) * tf.cast(tf.logical_not(y_pred), tf.float32), \n","                       axis = 1)\n","    #calculating the accuracy score\n","    return (tp + tn)/(tp + tn + fp + fn + epsilon)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Constructing the Neural Network Architecture"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:41:42.914660Z","iopub.status.busy":"2023-01-13T01:41:42.913793Z","iopub.status.idle":"2023-01-13T01:41:42.938944Z","shell.execute_reply":"2023-01-13T01:41:42.937288Z","shell.execute_reply.started":"2023-01-13T01:41:42.914615Z"},"trusted":true},"outputs":[],"source":["# Importing different optimization algorithms from tensorflow.keras.optimizers\n","from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop\n","\n","# Instantiate the optimizer objects\n","optimizer_Adam = Adam()\n","optimizer_Adagrad = Adagrad()\n","optimizer_RMSprop = RMSprop()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-13T01:41:42.941591Z","iopub.status.busy":"2023-01-13T01:41:42.940685Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-13 01:41:42.983635: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","2023-01-13 01:41:47.862183: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","253/253 [==============================] - 259s 1s/step - loss: 0.2305 - fbeta: 0.6427 - accuracy_score: 0.9120 - val_loss: 0.2767 - val_fbeta: 0.6110 - val_accuracy_score: 0.9067\n","Epoch 2/20\n","253/253 [==============================] - 250s 989ms/step - loss: 0.1923 - fbeta: 0.7032 - accuracy_score: 0.9254 - val_loss: 0.2249 - val_fbeta: 0.6657 - val_accuracy_score: 0.9123\n","Epoch 3/20\n","253/253 [==============================] - 249s 983ms/step - loss: 0.1744 - fbeta: 0.7329 - accuracy_score: 0.9315 - val_loss: 0.1613 - val_fbeta: 0.7476 - val_accuracy_score: 0.9359\n","Epoch 4/20\n","253/253 [==============================] - 246s 971ms/step - loss: 0.1637 - fbeta: 0.7503 - accuracy_score: 0.9355 - val_loss: 0.1564 - val_fbeta: 0.7562 - val_accuracy_score: 0.9392\n","Epoch 5/20\n","220/253 [=========================>....] - ETA: 30s - loss: 0.1575 - fbeta: 0.7614 - accuracy_score: 0.9382"]}],"source":["# Define The Model\n","model = keras.Sequential()\n","\n","# Adding The Layers\n","# Batch Normalization layer is added as the first layer of the model, which normalize the input data.\n","model.add(BatchNormalization(input_shape=(64, 64, 3)))\n","\n","# Convolutional layers and MaxPooling layers are added to extract features from the input images and reduce the spatial dimensions of the feature maps respectively.\n","model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Dropout layers are added to prevent overfitting.\n","model.add(Dropout(0.2))\n","\n","# Same set of layers are added for the next set of features\n","model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","# Flatten layer is added to convert the 2D feature maps into a 1D feature vector\n","model.add(Flatten())\n","\n","# Fully connected layers (dense layers) and dropout layers are added\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(17, activation='sigmoid'))\n","\n","# Compiling the model by specifying the loss function, optimizer, and evaluation metrics\n","model.compile(optimizer=optimizer_RMSprop,\n","              loss='binary_crossentropy',\n","              metrics=[fbeta, accuracy_score])\n","\n","# Training the model on the training data for 5 epoch with a batch size of 128, and validating the model on the validation data\n","history = model.fit(x_train, y_train,\n","                      batch_size=128,\n","                      epochs=20,\n","                      verbose=1,\n","                      validation_data=(x_val, y_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plotting the training and validation loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","\n","# Adding title, y-label and x-label to the plot\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","\n","# Adding legend to the plot\n","plt.legend(['train', 'validation'], loc='upper left')\n","\n","# Showing the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Evaluate the model on the validation set\n","model.evaluate(x_val, y_val)\n","\n","# Calculate the f-beta score for the training set\n","train_fscore = fbeta_score(y_train, np.round(model.predict(x_train)), beta=2,average = 'weighted')\n","print(\"train fscore: \", train_fscore)\n","\n","# Calculate the f-beta score for the validation set\n","val_fscore = fbeta_score(y_val, np.round(model.predict(x_val)), beta=2, average = 'weighted')\n","print(\"val fscore: \", val_fscore)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluating The Model Using The Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Read the sample submission CSV file and store it in a DataFrame\n","df_samplesub = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\n","\n","# The DataFrame 'df_samplesub' now contains the data from the sample submission CSV file\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create two separate DataFrames for the test and additional test files\n","\n","# The first DataFrame will contain the labels for the test-jpg files\n","test = df_samplesub[0 : 40669]\n","\n","# The second DataFrame will contain the labels for the test-jpg-additional files\n","files = df_samplesub[40669 : ]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Loading the test images\n","\n","# Initialize an empty list to store the images\n","test_img = []\n","\n","# Loop through the test DataFrame\n","for image_name, tags in tqdm(test.values, miniters=1000):\n","    # Read the image file\n","    arr = cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(image_name))\n","    # Resize the image to (64, 64)\n","    test_img.append(cv2.resize(arr, (64, 64)))\n","\n","# Loop through the additional test files DataFrame\n","for image_name, tags in tqdm(files.values, miniters=1000):\n","    # Read the image file\n","    arr = cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(image_name))\n","    # Resize the image to (64, 64)\n","    test_img.append(cv2.resize(arr, (64, 64)))\n","\n","# Convert the list of images to a numpy array and normalize the pixel values\n","test_img = np.array(test_img, np.float16)/255.0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Free up some memory that is not being used by the program.. again\n","gc.collect()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Running the predictions\n","\n","# Initialize an empty list to store the predictions\n","yres = []\n","\n","# Make predictions on the test images using the model\n","predictions = model.predict(test_img, batch_size = 64, verbose = 2)\n","\n","# Append the predictions to the yres list\n","yres.append(predictions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Free up some memory that is not being used by the program.. again again\n","gc.collect()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Configuring The Submission File"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Convert the encoded labels back to their original form\n","\n","# Initialize an empty array to store the decoded labels\n","sub = np.array(yres[0])\n","\n","# Loop through the encoded labels\n","for i in range (1, len(yres)):\n","    # Add the encoded label to the array\n","    sub += np.array(yres[i])\n","\n","# Convert the array to a DataFrame\n","sub = pd.DataFrame(sub, columns = label_map)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create the submission file format\n","\n","# Initialize an empty list to store the predictions\n","preds = []\n","\n","# Loop through the sample submission DataFrame\n","for i in tqdm(range(sub.shape[0]), miniters=1000):\n","    # Get the i-th row of the DataFrame\n","    a = sub.loc[[i]]\n","    # Apply a lambda function to get a Boolean array indicating which columns have values greater than 0.2\n","    a = a.apply(lambda x: x > 0.2, axis=1)\n","    # Transpose the DataFrame\n","    a = a.transpose()\n","    # Get the rows where the Boolean array is True\n","    a= a.loc[a[i] == True]\n","    # Join the index of the DataFrame (which contains the tags) into a single string\n","    ' '.join(list(a.index))\n","    # Append the string of tags to the preds list\n","    preds.append(' '.join(list(a.index)))\n","\n","# Assign the preds list as the 'tags' column of the sample submission DataFrame\n","df_samplesub['tags'] = preds\n","\n","# Save the sample submission DataFrame to a CSV file\n","df_samplesub.to_csv('CMT_submissionfile.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
